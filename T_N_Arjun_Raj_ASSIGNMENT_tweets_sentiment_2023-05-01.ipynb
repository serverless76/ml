{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "KEmoub7HNkev"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "yUmC2ue2N9zr"
      },
      "outputs": [],
      "source": [
        "tweets_data = pd.read_csv('tweets.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dmrpd7oOHuy",
        "outputId": "f64a2a82-5d72-4bfe-cfa7-74fb23e6e2b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7920, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "tweets_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "YjMwfa7XpSTI"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7FzXEhKOJ-6",
        "outputId": "5a67f2c3-e917-453d-ed3d-6708e165fda3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'label', 'tweet'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "tweets_data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "iIfGRl7PONIW",
        "outputId": "986bae51-c054-4c43-b582-bbd440cb0909"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    id  label                                              tweet\n",
              "0    1      0  #fingerprint #Pregnancy Test https://goo.gl/h1...\n",
              "1    2      0  Finally a transparant silicon case ^^ Thanks t...\n",
              "2    3      0  We love this! Would you go? #talk #makememorie...\n",
              "3    4      0  I'm wired I know I'm George I was made that wa...\n",
              "4    5      1  What amazing service! Apple won't even talk to...\n",
              "5    6      1  iPhone software update fucked up my phone big ...\n",
              "6    7      0  Happy for us .. #instapic #instadaily #us #son...\n",
              "7    8      0  New Type C charger cable #UK http://www.ebay.c...\n",
              "8    9      0  Bout to go shopping again listening to music #...\n",
              "9   10      0  Photo: #fun #selfie #pool #water #sony #camera...\n",
              "10  11      1  hey #apple when you make a new ipod dont make ...\n",
              "11  12      1  Ha! Not heavy machinery but it does what I nee...\n",
              "12  13      1  Contemplating giving in to the iPhone bandwago...\n",
              "13  14      0  I just made another crazy purchase lol my theo...\n",
              "14  15      1  @shaqlockholmes @sam_louise1991 the battery is..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2ef37fe4-5bce-47fe-a1f3-1dbe94177635\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Finally a transparant silicon case ^^ Thanks t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>We love this! Would you go? #talk #makememorie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>I'm wired I know I'm George I was made that wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>What amazing service! Apple won't even talk to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>iPhone software update fucked up my phone big ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>Happy for us .. #instapic #instadaily #us #son...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>New Type C charger cable #UK http://www.ebay.c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>Bout to go shopping again listening to music #...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>Photo: #fun #selfie #pool #water #sony #camera...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>hey #apple when you make a new ipod dont make ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>Ha! Not heavy machinery but it does what I nee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>Contemplating giving in to the iPhone bandwago...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>I just made another crazy purchase lol my theo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>@shaqlockholmes @sam_louise1991 the battery is...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ef37fe4-5bce-47fe-a1f3-1dbe94177635')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2ef37fe4-5bce-47fe-a1f3-1dbe94177635 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2ef37fe4-5bce-47fe-a1f3-1dbe94177635');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "tweets_data.head(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ulW5nHEiOQNl",
        "outputId": "3555ccfd-31a8-4b23-8795-7d7acfa7f9f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"What amazing service! Apple won't even talk to me about a question I have unless I pay them $19.95 for their stupid support!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "tweets_data['tweet'][4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "xwqaU66_OUPG"
      },
      "outputs": [],
      "source": [
        "# tweets_data['label'][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W637aCZkObvI",
        "outputId": "a84d31b5-9ff5-4e63-87a0-71f4a48e9a8c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    5894\n",
              "1    2026\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "tweets_data['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "4DzD0FDTLNpK"
      },
      "outputs": [],
      "source": [
        "tweets_data=tweets_data.drop('id',axis=1)\n",
        "X=tweets_data.drop('label',axis=1)\n",
        "y=tweets_data['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "ei3JFdj5LNpL"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train,y_test = train_test_split(X,y,test_size=0.2, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t811NvOorF2e",
        "outputId": "7950c31a-66c6-4a9a-d335-913e9dce387b"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "bvgU_zqwLNpM"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "#Removing the html strips\n",
        "def strip_html(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    return soup.get_text()\n",
        "\n",
        "#Removing the square brackets\n",
        "def remove_between_square_brackets(text):\n",
        "    return re.sub('\\[[^]]*\\]', '', text)\n",
        "\n",
        "#Removing the noisy text\n",
        "def denoise_text(text):\n",
        "    text = strip_html(text)\n",
        "    text = remove_between_square_brackets(text)\n",
        "    return text\n",
        "\n",
        "\n",
        "#Define function for removing special characters\n",
        "def remove_special_characters(text, remove_digits=True):\n",
        "    pattern=r'[^a-zA-z0-9\\s]'\n",
        "    text=re.sub(pattern,'',text)\n",
        "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"can't\", \"cannot \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"I'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\",\", \" \", text)\n",
        "    text = re.sub(r\"\\.\", \" \", text)\n",
        "    text = re.sub(r\"!\", \" ! \", text)\n",
        "    text = re.sub(r\"\\^^\", \"\", text)\n",
        "    text = re.sub(r\"\\/\", \" \", text)\n",
        "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
        "    text = re.sub(r\"\\+\", \" + \", text)\n",
        "    text = re.sub(r\"\\-\", \" - \", text)\n",
        "    text = re.sub(r\"\\=\", \" = \", text)\n",
        "    text = re.sub(r\"'\", \" \", text)\n",
        "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
        "    text = re.sub(r\":\", \" : \", text)\n",
        "    text = re.sub(r\" e g \", \" eg \", text)\n",
        "    text = re.sub(r\" b g \", \" bg \", text)\n",
        "    text = re.sub(r\" u s \", \" american \", text)\n",
        "    text = re.sub(r\"\\0s\", \"0\", text)\n",
        "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
        "    text = re.sub(r\"e - mail\", \"email\", text)\n",
        "    text = re.sub(r\"j k\", \"jk\", text)\n",
        "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "    return text\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    lem=nltk.stem.wordnet.WordNetLemmatizer()\n",
        "    text= ' '.join([lem.lemmatize(word) for word in text.split()])\n",
        "    return text\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "6-KBTC87OmV7"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import FeatureUnion, Pipeline\n",
        "from gensim.utils import simple_preprocess\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "class DummyTransformer(BaseEstimator,TransformerMixin):\n",
        "    \n",
        "    '''\n",
        "    dummy class to inherit from to avoid typing the fit method for everything\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        return None\n",
        "    def fit(self,X=None,y=None):\n",
        "        return self\n",
        "    def transform(self,X=None):\n",
        "        return X\n",
        "    \n",
        "def do_basic_text_preprocessing(text:str):\n",
        "    preprocessed_text=denoise_text(text)\n",
        "    preprocessed_text=remove_special_characters(preprocessed_text)\n",
        "    # preprocessed_text=lemmatize_text(preprocessed_text)\n",
        "\n",
        "    return preprocessed_text\n",
        "\n",
        "class TextPreprocessor(DummyTransformer):\n",
        "    def transform(self,X:pd.DataFrame):\n",
        "#         preprocessed_X_np_array=X.apply(do_basic_text_preprocessing).values\n",
        "        # preprocessed_X_nparr=X['tweet'].apply(lambda x:do_basic_text_preprocessing(x)).values\n",
        "        preprocessed_X_df=X['tweet'].apply(lambda x:do_basic_text_preprocessing(x))\n",
        "        return preprocessed_X_df\n",
        "\n",
        "class Tokenizer(DummyTransformer):\n",
        "    def transform(self, X):\n",
        "        X=pd.DataFrame(X)\n",
        "        # print(X.info())\n",
        "        # print(X)\n",
        "        X_tokenized=X['tweet'].apply(lambda x:simple_preprocess(x))\n",
        "        # X_tokenized=X.apply(word_tokenize,axis=0) ## requires downloading punkt\n",
        "        # print(X_tokenized)\n",
        "        return X_tokenized\n",
        "\n",
        "class SparseToDenseArr(DummyTransformer):\n",
        "    def transform(self,X=None):\n",
        "#         preprocessed_X_np_array=X.apply(do_basic_text_preprocessing).values\n",
        "        dense_arr=X.toarray()\n",
        "\n",
        "        return dense_arr    \n",
        "\n",
        "class MetaFeatureEngineer(DummyTransformer):\n",
        "    def transform(self, X=None,y=None):\n",
        "        return None\n",
        "\n",
        "tfidf_meta_union_inst=FeatureUnion([('tfidf',TfidfVectorizer()),('metafeature',MetaFeatureEngineer())])\n",
        "    \n",
        "tfidf_pipeline=Pipeline([('textpreprocessor',TextPreprocessor()),('tfidf_meta_union_inst',tfidf_meta_union_inst),('sparsetodense',SparseToDenseArr())])\n",
        "\n",
        "# tfidf_pipeline=Pipeline([('textpreprocessor',TextPreprocessor()),('tfidf',TfidfVectorizer()),('sparsetodense',SparseToDenseArr())])\n",
        "\n",
        "\n",
        "bow_meta_union_inst=FeatureUnion([('bow',CountVectorizer()),('metafeature',MetaFeatureEngineer())])\n",
        "    \n",
        "bow_pipeline=Pipeline([('textpreprocessor',TextPreprocessor()),('bow_meta_union_inst',bow_meta_union_inst)])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### word2vec\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "class CustomWord2VecTransformer(DummyTransformer):\n",
        "    # def __init__(self,vector_size = 300, window = 6 , min_count = 3, sg = 0):\n",
        "    def __init__(self,**kwargs):\n",
        "        self.input_args=kwargs\n",
        "        # self.w2v_model=None\n",
        "\n",
        "        # allowed_keys=['vector_size','window','min_count','sg']\n",
        "        # self.__dict__.update((k, v) for k, v in kwargs.items() if k in allowed_keys)\n",
        "\n",
        "\n",
        "\n",
        "    def fit(self,X,y=None):\n",
        "        self.w2v_model=Word2Vec(X,**self.input_args)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def get_mean_embedding_for_doc(self,doc_tokens):\n",
        "        model=self.w2v_model   \n",
        "        embeddings=[]\n",
        "        for tok in doc_tokens:\n",
        "            if tok in model.wv.index_to_key:\n",
        "                embeddings.append(model.wv.get_vector(tok))\n",
        "        return np.mean(embeddings,axis=0)\n",
        "\n",
        "    \n",
        "    def transform(self, X):\n",
        "\n",
        "        X_transformed=X.apply(lambda x:self.get_mean_embedding_for_doc(x))\n",
        "        X_transformed=pd.DataFrame(X_transformed.tolist())\n",
        "        # print(X_transformed)\n",
        "        return X_transformed\n",
        "\n",
        "\n",
        "class GoogleWord2VecTransformer(DummyTransformer):\n",
        "    # def __init__(self,vector_size = 300, window = 6 , min_count = 3, sg = 0):\n",
        "    def __init__(self,*args,**kwargs):\n",
        "        self.w2vmodel=KeyedVectors.load_word2vec_format(*args,**kwargs)\n",
        "\n",
        "        self.input_args=kwargs\n",
        "        # allowed_keys=['vector_size','window','min_count','sg']\n",
        "        # self.__dict__.update((k, v) for k, v in kwargs.items() if k in allowed_keys)\n",
        "\n",
        "\n",
        "    def fit(self,X,y=None):\n",
        "        \n",
        "        return self\n",
        "\n",
        "    def get_mean_embedding_for_doc(self,doc_tokens):\n",
        "        model=self.w2vmodel\n",
        "        embeddings=[]\n",
        "        for tok in doc_tokens:\n",
        "            if tok in model: ## note the synatx to get vector etc. are different from that for gensim model\n",
        "                embeddings.append(model[tok])\n",
        "        return np.mean(embeddings,axis=0)\n",
        "\n",
        "\n",
        "    def transform(self, X):\n",
        "        X_transformed=X.apply(lambda x:self.get_mean_embedding_for_doc(x))\n",
        "        X_transformed=pd.DataFrame(X_transformed.tolist())\n",
        "        return X_transformed\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l5QeS7fn_z0N"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# google_meta_union_inst=FeatureUnion([\n",
        "#     ('google',GoogleWord2VecTransformer(\"/content/drive/MyDrive/ml-ai files arjun/GoogleNews-vectors-negative300.bin\",binary=True)),\n",
        "#     ('metafeature',MetaFeatureEngineer())])\n",
        "\n",
        "# google_trans_inst=GoogleWord2VecTransformer(\"/content/drive/MyDrive/ml-ai files arjun/GoogleNews-vectors-negative300.bin\",binary=True)\n"
      ],
      "metadata": {
        "id": "GUsKjP5M5mlm"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# google_pipeline=Pipeline([('textpreprocessor',TextPreprocessor()),('tokenizer',Tokenizer()),('google',google_trans_inst())])\n",
        "custom_w2v_pipeline=Pipeline([('textpreprocessor',TextPreprocessor()),('tokenizer',Tokenizer()),('customw2v',CustomWord2VecTransformer())])\n"
      ],
      "metadata": {
        "id": "53abysqYbRlT"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "uoRTwMI4LNpP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85da0c26-2f69-4f18-a5bc-a35a529bbde0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-106-528d8e3112de>:5: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  soup = BeautifulSoup(text, \"html.parser\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            0         1         2         3         4         5         6   \\\n",
            "0    -0.101155  0.293836 -0.009673  0.109925  0.202355 -0.369149  0.028533   \n",
            "1     0.222628  0.349493 -0.427015  0.484218  0.215723 -1.733066  0.001228   \n",
            "2    -0.166048  0.360263  0.006424  0.135612  0.281680 -0.422261  0.014386   \n",
            "3    -0.046643  0.502848  0.013319  0.180812  0.241929 -0.612826  0.155780   \n",
            "4    -0.164313  0.410249  0.013402  0.153985  0.302769 -0.481192  0.040237   \n",
            "...        ...       ...       ...       ...       ...       ...       ...   \n",
            "6331 -0.164654  0.443424  0.138773  0.150636  0.239597 -0.423581  0.082000   \n",
            "6332 -0.067155  0.385732  0.005339  0.144759  0.180914 -0.444660  0.114349   \n",
            "6333 -0.199630  0.425910  0.024032  0.157504  0.334407 -0.487582  0.011459   \n",
            "6334  0.027704  0.271478 -0.041143  0.140804  0.093746 -0.484550  0.092072   \n",
            "6335  0.083316  0.336840 -0.025756  0.145630  0.040891 -0.521666  0.146156   \n",
            "\n",
            "            7         8         9   ...        90        91        92  \\\n",
            "0     0.616504 -0.214794 -0.179059  ...  0.230175  0.163360  0.075107   \n",
            "1     2.093114 -1.031276 -0.511968  ... -0.083797  1.103910  0.134651   \n",
            "2     0.769661 -0.222742 -0.233568  ...  0.305141  0.157530  0.103433   \n",
            "3     0.903730 -0.432625 -0.222260  ...  0.482362  0.273647  0.129626   \n",
            "4     0.840879 -0.275503 -0.243936  ...  0.356319  0.188736  0.117046   \n",
            "...        ...       ...       ...  ...       ...       ...       ...   \n",
            "6331  0.675870 -0.325504 -0.235759  ...  0.432468  0.195912  0.076320   \n",
            "6332  0.642872 -0.300083 -0.193761  ...  0.291995  0.226673  0.088677   \n",
            "6333  0.901998 -0.276650 -0.271139  ...  0.364224  0.188121  0.119573   \n",
            "6334  0.602095 -0.341195 -0.143864  ...  0.181945  0.275388  0.065544   \n",
            "6335  0.558188 -0.419316 -0.118694  ...  0.215450  0.308322  0.055787   \n",
            "\n",
            "            93        94        95        96        97        98        99  \n",
            "0     0.123214  0.488906  0.286545  0.106925 -0.277922 -0.008596 -0.095815  \n",
            "1     0.300732  0.631295  0.523534 -0.360484 -0.421230  1.011042  0.333859  \n",
            "2     0.163831  0.646303  0.390165  0.172116 -0.355589 -0.062034 -0.150284  \n",
            "3     0.155056  0.707682  0.307197  0.114918 -0.421767 -0.036859 -0.118241  \n",
            "4     0.170740  0.699392  0.404990  0.178366 -0.391117 -0.067797 -0.153722  \n",
            "...        ...       ...       ...       ...       ...       ...       ...  \n",
            "6331  0.156682  0.666032  0.385156  0.120021 -0.371444 -0.045943 -0.121089  \n",
            "6332  0.141267  0.549039  0.273295  0.099040 -0.320257 -0.019633 -0.100586  \n",
            "6333  0.191534  0.764095  0.469626  0.187770 -0.416024 -0.056362 -0.168891  \n",
            "6334  0.097792  0.360581  0.168469 -0.016945 -0.230262  0.122144  0.006469  \n",
            "6335  0.088386  0.342303  0.112880 -0.055936 -0.241110  0.122051  0.026953  \n",
            "\n",
            "[6336 rows x 100 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-106-528d8e3112de>:5: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  soup = BeautifulSoup(text, \"html.parser\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            0         1         2         3         4         5         6   \\\n",
            "0     0.069610  0.483735 -0.056395  0.229231  0.116981 -0.791935  0.176551   \n",
            "1    -0.083927  0.322315  0.031219  0.131417  0.173827 -0.395406  0.067908   \n",
            "2    -0.052664  0.349686  0.027953  0.133387  0.169093 -0.412658  0.097112   \n",
            "3    -0.126973  0.436715  0.001226  0.161286  0.250006 -0.504830  0.076913   \n",
            "4    -0.107375  0.320135  0.008699  0.138838  0.230793 -0.439413  0.026094   \n",
            "...        ...       ...       ...       ...       ...       ...       ...   \n",
            "1579 -0.066843  0.441214  0.069046  0.172105  0.141570 -0.451384  0.184120   \n",
            "1580 -0.121269  0.364146  0.065761  0.141776  0.227400 -0.392874  0.060282   \n",
            "1581 -0.076825  0.373910  0.072218  0.132286  0.175032 -0.375872  0.108198   \n",
            "1582  0.015625  0.519374 -0.018821  0.168604  0.132834 -0.598176  0.225431   \n",
            "1583 -0.060434  0.438656  0.051149  0.180651  0.166148 -0.483273  0.164463   \n",
            "\n",
            "            7         8         9   ...        90        91        92  \\\n",
            "0     0.953259 -0.598505 -0.224929  ...  0.319686  0.453216  0.099592   \n",
            "1     0.583997 -0.264198 -0.174693  ...  0.266701  0.194725  0.068017   \n",
            "2     0.607970 -0.287876 -0.162122  ...  0.312876  0.187275  0.087840   \n",
            "3     0.842470 -0.319916 -0.241821  ...  0.365130  0.222068  0.103558   \n",
            "4     0.708458 -0.267747 -0.205834  ...  0.266308  0.197644  0.087870   \n",
            "...        ...       ...       ...  ...       ...       ...       ...   \n",
            "1579  0.618743 -0.358512 -0.179185  ...  0.384891  0.258052  0.088221   \n",
            "1580  0.637581 -0.263890 -0.197093  ...  0.331286  0.165398  0.091372   \n",
            "1581  0.529326 -0.275839 -0.176257  ...  0.313620  0.182464  0.067848   \n",
            "1582  0.774583 -0.480628 -0.190813  ...  0.416700  0.323853  0.101883   \n",
            "1583  0.667088 -0.349450 -0.184371  ...  0.379330  0.254845  0.087242   \n",
            "\n",
            "            93        94        95        96        97        98        99  \n",
            "0     0.160968  0.579583  0.246184 -0.037968 -0.392184  0.197692  0.011124  \n",
            "1     0.126984  0.478038  0.263446  0.066784 -0.279127  0.005800 -0.076243  \n",
            "2     0.116276  0.503478  0.237181  0.075892 -0.297396 -0.030585 -0.083540  \n",
            "3     0.170854  0.701641  0.378169  0.161928 -0.402003 -0.056013 -0.142929  \n",
            "4     0.139020  0.544615  0.327078  0.097154 -0.303885  0.017658 -0.084866  \n",
            "...        ...       ...       ...       ...       ...       ...       ...  \n",
            "1579  0.145036  0.573544  0.251077  0.036483 -0.341353 -0.053186 -0.088056  \n",
            "1580  0.136824  0.568651  0.317965  0.112251 -0.322483 -0.040284 -0.106746  \n",
            "1581  0.126873  0.491732  0.256261  0.069658 -0.288134 -0.017204 -0.073943  \n",
            "1582  0.140700  0.638260  0.216975  0.095981 -0.398240 -0.024981 -0.110907  \n",
            "1583  0.141486  0.581569  0.264151  0.045169 -0.352841 -0.043390 -0.068609  \n",
            "\n",
            "[1584 rows x 100 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "X_train_tfidf=custom_w2v_pipeline.fit_transform(X_train)\n",
        "X_test_tfidf=custom_w2v_pipeline.transform(X_test)\n",
        "\n",
        "# X_train=TextPreprocessor().transform(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "_2YZPpH5LNpR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ed43e8e-7f9d-4a23-aa9a-2834624ceff1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0     1130\n",
            "1     6336\n",
            "2     4320\n",
            "3     6336\n",
            "4     6330\n",
            "      ... \n",
            "95    6258\n",
            "96    5701\n",
            "97       0\n",
            "98    2335\n",
            "99     442\n",
            "Length: 100, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(np.sum(X_train_tfidf >0))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### pass parameters to Pipeline steps"
      ],
      "metadata": {
        "id": "NNfCepzfTT54"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "nC7OHsTbLNpR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "81c31e56-4fa5-4fe1-e8a6-d5db1c8043b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          GaussianNB  DecisionTreeClassifier  LogisticRegression\n",
              "accuracy    0.677399                0.613636            0.744949"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-220d9903-7166-4927-91a6-0c02ea80c8a6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GaussianNB</th>\n",
              "      <th>DecisionTreeClassifier</th>\n",
              "      <th>LogisticRegression</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>accuracy</th>\n",
              "      <td>0.677399</td>\n",
              "      <td>0.613636</td>\n",
              "      <td>0.744949</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-220d9903-7166-4927-91a6-0c02ea80c8a6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-220d9903-7166-4927-91a6-0c02ea80c8a6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-220d9903-7166-4927-91a6-0c02ea80c8a6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ],
      "source": [
        "from importlib import import_module\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "\n",
        "\n",
        "\n",
        "# algos=[('naive_bayes','GaussianNB'),('tree','DecisionTreeClassifier'),('linear_model','LogisticRegression')]\n",
        "# algos=[('linear_model','LogisticRegression')] ### why did i even do this?\n",
        "\n",
        "result_dict={}\n",
        "X_train_to_use=X_train_tfidf\n",
        "X_test_to_use=X_test_tfidf\n",
        "y_train_to_use=y_train\n",
        "y_test_to_use=y_test\n",
        "\n",
        "algo_insts=[GaussianNB(),DecisionTreeClassifier(),LogisticRegression()]\n",
        "\n",
        "for algo_inst in algo_insts:\n",
        "    algo_inst.fit(X_train_to_use, y_train_to_use)\n",
        "    y_pred=algo_inst.predict(X_test_to_use)\n",
        "    result_dict.update({f'{type(algo_inst).__name__}':{'accuracy':accuracy_score(y_pred,y_test_to_use)}})\n",
        "pd.DataFrame(result_dict)\n",
        "\n",
        "\n",
        "# for algo in algos:\n",
        "#     ## apparently the methods of the module are attributes of the obj outputted by import_module\n",
        "#     class_var=getattr(import_module(f'sklearn.{algo[0]}'),algo[1]) \n",
        "#     clf=class_var()\n",
        "#     # clf=module.\n",
        "#     clf.fit(X_train_to_use, y_train_to_use)\n",
        "#     y_pred=clf.predict(X_test_to_use)\n",
        "#     result_dict.update({f'{type(clf).__name__}':{'accuracy':accuracy_score(y_pred,y_test_to_use)}})\n",
        "# pd.DataFrame(result_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "id": "JQk3x_TGOxLQ"
      },
      "outputs": [],
      "source": [
        "#### preprocess the text to that is in the required format for word2vec\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "wmFBQDV4PixS"
      },
      "outputs": [],
      "source": [
        "# print(simple_preprocess(tweets_data['tweet'][1])[:30])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "id": "XG4eFXVFPtTf"
      },
      "outputs": [],
      "source": [
        "preprocessed_tweet = tweets_data['tweet'].apply(lambda x: simple_preprocess(x, min_len = 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "id": "9mzTwbfBQMrb"
      },
      "outputs": [],
      "source": [
        "# preprocessed_tweet.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "id": "6KjdXaatQfey"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "O3jt0aytQsf7"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "cbow_w2v_model = Word2Vec(preprocessed_tweet, vector_size = 300, window = 6 , min_count = 3, sg = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "id": "q2GxtrMdRvZf"
      },
      "outputs": [],
      "source": [
        "skgram_w2v_model = Word2Vec(preprocessed_tweet, vector_size = 300, window = 6, min_count = 3, sg = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "id": "swlS17vjSHsi"
      },
      "outputs": [],
      "source": [
        "### vocubulary size "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "id": "3VDAIK1mSjib"
      },
      "outputs": [],
      "source": [
        "# print(\"cbow vocabulary size is: \",len(cbow_w2v_model.wv.index_to_key))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "fCS3YjnESmGR"
      },
      "outputs": [],
      "source": [
        "# print(\"skipgram vocabulary size is: \",len(skgram_w2v_model.wv.index_to_key))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "id": "POSotfQ3TBkl"
      },
      "outputs": [],
      "source": [
        "# print(cbow_w2v_model.wv.index_to_key[:35])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "Ip9Hny4KTIRW"
      },
      "outputs": [],
      "source": [
        "### vocub and the index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "id": "ldWQ8P4wTfWl"
      },
      "outputs": [],
      "source": [
        "# list(cbow_w2v_model.wv.key_to_index.items())[:35]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "id": "XtWgQNzRToDV"
      },
      "outputs": [],
      "source": [
        "### \"warning\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "id": "SyHVOESCUHmZ"
      },
      "outputs": [],
      "source": [
        "# cbow_w2v_model.wv.get_vector(\"warning\").shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "id": "EWX9iugCUQtt"
      },
      "outputs": [],
      "source": [
        "# cbow_w2v_model.wv.get_vector(\"defence\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "id": "1fwzWLsQUgZF"
      },
      "outputs": [],
      "source": [
        "# cbow_w2v_model.wv.most_similar(\"transparent\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "id": "BrCXex-nVrFK"
      },
      "outputs": [],
      "source": [
        "# skgram_w2v_model.wv.most_similar(\"transparent\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "id": "2hOQkDw_V3T0"
      },
      "outputs": [],
      "source": [
        "# cbow_w2v_model.wv.most_similar(\"web\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "id": "Neb3PhAlWCjH"
      },
      "outputs": [],
      "source": [
        "# skgram_w2v_model.wv.most_similar(\"web\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {
        "id": "I3H1vVp6WZzk"
      },
      "outputs": [],
      "source": [
        "# skgram_w2v_model.wv.most_similar(\"fingerprint\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "id": "lAmBxWXFWn-3"
      },
      "outputs": [],
      "source": [
        "# skgram_w2v_model.wv.most_similar(\"camera\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {
        "id": "A0h8l9lOWuFb"
      },
      "outputs": [],
      "source": [
        "# model = cbow_w2v_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "id": "ylmNoOHZXPm1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "a842fdb9-38a4-4ccb-db04-8ad931c866f4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-201-5b5e9339ca7c>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/ml-ai files arjun/GoogleNews-vectors-negative300.bin\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgoogle_w2v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[1;32m   1717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m         \"\"\"\n\u001b[0;32m-> 1719\u001b[0;31m         return _load_word2vec_format(\n\u001b[0m\u001b[1;32m   1720\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1721\u001b[0m             \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[1;32m   2063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2064\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2065\u001b[0;31m             _word2vec_read_binary(\n\u001b[0m\u001b[1;32m   2066\u001b[0m                 \u001b[0mfin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_chunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2067\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m_word2vec_read_binary\u001b[0;34m(fin, kv, counts, vocab_size, vector_size, datatype, unicode_errors, binary_chunk_size, encoding)\u001b[0m\n\u001b[1;32m   1956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1957\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mtot_processed_words\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1958\u001b[0;31m         \u001b[0mnew_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary_chunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1959\u001b[0m         \u001b[0mchunk\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnew_chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m         processed_words, chunk = _add_bytes_to_kv(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "filename = \"/content/drive/MyDrive/ml-ai files arjun/GoogleNews-vectors-negative300.bin\"\n",
        "from gensim.models import KeyedVectors\n",
        "google_w2v = KeyedVectors.load_word2vec_format(filename, binary = True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1eQrNOJwVazV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvuXnDTzXSwG"
      },
      "outputs": [],
      "source": [
        "def get_embedding_w2v(doc_tokens, pretrained):\n",
        "  embeddings = []\n",
        "  if pretrained:\n",
        "      for tok in doc_tokens:\n",
        "          if tok in google_w2v:\n",
        "              embeddings.append(google_w2v[tok])\n",
        "  else:\n",
        "      model = cbow_w2v_model\n",
        "      for tok in doc_tokens:\n",
        "        if tok in model.wv.index_to_key:\n",
        "          embeddings.append(model.wv.get_vector(tok))\n",
        "\n",
        "  return np.mean(embeddings, axis = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vk93CPfQjJW3"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "tweets_data[\"label\"] = le.fit_transform(tweets_data['label'])\n",
        "y = tweets_data['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dHIoFe1jJuD"
      },
      "outputs": [],
      "source": [
        "X_w2v_model = preprocessed_tweet.apply(lambda x: get_embedding_w2v(x,0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EW8VKG3OYGlk"
      },
      "outputs": [],
      "source": [
        "# X_w2v_model = preprocessed_tweet.apply(lambda x: get_embedding_w2v(x,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ImreAwdYYXd"
      },
      "outputs": [],
      "source": [
        "X_w2v_model = pd.DataFrame(X_w2v_model.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6okL6bzLZYna"
      },
      "outputs": [],
      "source": [
        "X_w2v_model.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0msML7naXBb"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bk33q0vdab6t"
      },
      "outputs": [],
      "source": [
        "x_train , x_test, y_train , y_test = train_test_split(X_w2v_model, \n",
        "                                                      y , \n",
        "                                                      test_size = 0.2,\n",
        "                                                      random_state = 144)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMOt4O7Waq3G"
      },
      "outputs": [],
      "source": [
        "#### naive bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Agfz-b5GavVh"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3qxz1oha0gV"
      },
      "outputs": [],
      "source": [
        "gnb = GaussianNB()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyM2GPiGa7FK"
      },
      "outputs": [],
      "source": [
        "gnb.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nbmc9bVpa9pp"
      },
      "outputs": [],
      "source": [
        "y_pred = gnb.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7xEaqUPr0Tt"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDnopeAYbBSB"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8qAiSwjbFRY"
      },
      "outputs": [],
      "source": [
        "accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLHaA5Gbfif9"
      },
      "outputs": [],
      "source": [
        "#### draw the plot in the 2d space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_Eoi58ykQPd"
      },
      "outputs": [],
      "source": [
        "### transparent, fingerprint, camera"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrrHVSezke-B"
      },
      "outputs": [],
      "source": [
        "transparent_cb = cbow_w2v_model.wv.most_similar(\"transparent\")\n",
        "fingerprint_cb = cbow_w2v_model.wv.most_similar(\"fingerprint\")\n",
        "camera_cb = cbow_w2v_model.wv.most_similar(\"camera\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qat8eCZFkv7O"
      },
      "outputs": [],
      "source": [
        "words_all = transparent_cb + fingerprint_cb + camera_cb\n",
        "words_all_list = list(map(lambda x:x[0], words_all))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9M0khNhlKzE"
      },
      "outputs": [],
      "source": [
        "words_all_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXr4pRpGmIsJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xl94nDeHlMez"
      },
      "outputs": [],
      "source": [
        "def plot_cbow_w2v(word_list):\n",
        "  x = cbow_w2v_model.wv[word_list]\n",
        "  pca = PCA(n_components = 2)\n",
        "  results = pca.fit_transform(x)\n",
        "\n",
        "  plt.scatter(results[:,0], results[:,1])\n",
        "  for i, word in enumerate(word_list):\n",
        "    plt.annotate(word, xy = (results[i,0], results[i,1]))\n",
        "  \n",
        "  plt.figure(figsize = (6,9))\n",
        "  plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5oLlvXWmQ3H"
      },
      "outputs": [],
      "source": [
        "plot_cbow_w2v(words_all_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbWuTCgrmWlj"
      },
      "outputs": [],
      "source": [
        "def plot_sg_w2v(word_list):\n",
        "  x = skgram_w2v_model.wv[word_list]\n",
        "  pca = PCA(n_components = 2)\n",
        "  results = pca.fit_transform(x)\n",
        "\n",
        "  plt.scatter(results[:,0], results[:,1])\n",
        "  for i, word in enumerate(word_list):\n",
        "    plt.annotate(word, xy = (results[i,0], results[i,1]))\n",
        "  \n",
        "  plt.figure(figsize = (6,9))\n",
        "  plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3aUiM4qnFcy"
      },
      "outputs": [],
      "source": [
        "plot_sg_w2v(words_all_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmJ6b2GgnJ8F"
      },
      "outputs": [],
      "source": [
        "### google accuracy 0.8118686868686869\n",
        "### cbow accuracy 0.8377525252525253\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}